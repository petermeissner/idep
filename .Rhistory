lapply( dbListConnections( dbDriver( drv = "MySQL")), dbDisconnect)
source("~/DBConnections/so_local.r")
#source("~/DBConnections/so_latin1_local.r")
#source("~/DBConnections/DBSOconnection.r")
}
# setting working directory
try(setwd("Z:/Gesch\u00e4ftsordnungen/database/rawdata"))
try(setwd("~/z/Database/rawdata"))
countries <- list.dirs(".", FALSE, FALSE)
countries
#### DEV >>>>
ctr <- "BEL"
#### <<<< DEV
# commandline argument evaluation
eval_cl_args()
if( !exists("ctr") ){
stop(
paste0(
"no country given choose one of these:\n",
paste0(countries, collapse = ", "),
"\ne.g.: R < file.R > file.rout --args ctr='AUT'"
)
)
}else{
message("### ============================================================== ###")
message("\n",ctr,"\n")
}
#### getting data ==============================================================
message("preparing data ... ")
# select linkage files
# link_files_select()
linkage_path <-
ifelse(
file.exists(ctr %.% "/coded"),
ctr %.% "/coded",
ctr %.% "/linked"
)
link_files_select(
list.files(linkage_path, full.names=T )
)
head(filelist_full,  1)
head(filelist_fname, 1)
head(filelist_path,  1)
country_path
country
# load linkage files
link_files_load(filelist_full)
linkage_env
ls(linkage_env001)
linkage_env
link_files_load(filelist_full)
link_files_load(filelist_full)
library(idep)
filelist_full
link_files_load(filelist_full)
library(idep)
env
library(idep)
env
env(1)
env(1)$RESULTS$oldtext
if( any(grepl("UTF-8", Sys.getlocale())) ){
for ( i in fl_seq )  {
Encoding(env(i)$RESULTS$oldtext) <- "latin1"
Encoding(env(i)$RESULTS$newtext) <- "latin1"
}
}
if( any(grepl("UTF-8", Sys.getlocale())) ){
for ( i in seq_along(filelist_path) )  {
Encoding(env(i)$RESULTS$oldtext) <- "latin1"
Encoding(env(i)$RESULTS$newtext) <- "latin1"
}
}
env(i)$RESULTS$oldtext
Encoding(env(i)$RESULTS$oldtext)
Encoding(env(i)$RESULTS$newtext)
i
length(filelist_full)
Encoding(env(i)$RESULTS$oldtext) <- "latin1"
env(i)
env(i,T)
eval_cl_args()
readLines("~/DBConnections/so_local.r")
# script for checking link data and uploading it to server
#### setting things up =========================================================
message("\n")
library(idep)
library(dplyr)
library(RMySQL)
'%.%' <- function(a,b) paste0(a,b)
message("\n")
# error handling
if( !interactive() ){
options(error = quote({email_error("undefined error in check and upload" , s=ctr, anyways=T); q(save = "no")}) )
}
# connection function
get_ready <- function(){
lapply( dbListConnections( dbDriver( drv = "MySQL")), dbDisconnect)
source("~/DBConnections/so_local.r")
#source("~/DBConnections/so_latin1_local.r")
#source("~/DBConnections/DBSOconnection.r")
}
# setting working directory
try(setwd("Z:/Gesch\u00e4ftsordnungen/database/rawdata"))
try(setwd("~/z/Database/rawdata"))
countries <- list.dirs(".", FALSE, FALSE)
countries
# commandline argument evaluation
eval_cl_args()
if( !exists("ctr") ){
stop(
paste0(
"no country given choose one of these:\n",
paste0(countries, collapse = ", "),
"\ne.g.: R < file.R > file.rout --args ctr='AUT'"
)
)
}else{
message("### ============================================================== ###")
message("\n",ctr,"\n")
}
ctr<-"AUT"
#### getting data ==============================================================
message("preparing data ... ")
# select linkage files
# link_files_select()
linkage_path <-
ifelse(
file.exists(ctr %.% "/coded"),
ctr %.% "/coded",
ctr %.% "/linked"
)
link_files_select(
list.files(linkage_path, full.names=T )
)
head(filelist_full,  1)
head(filelist_fname, 1)
head(filelist_path,  1)
country_path
country
# load linkage files
link_files_load(filelist_full)
linkage_env
ls(linkage_env001)
# select corpus file
# corpus_file_select()
corpus_file_select(
list.files(
paste0(ctr,"/corpus"),
full.names=T
)
)
corpus_file_full
corpus_file_fname
corpus_file_path
# load corpus file
corpus_file_load()
ls(corpus_env)
# preapre data for matching
corpus_data_prepare()
file.info(filelist_full)$mtime
file.info(paste0(ctr,".Rdata"))$mtime
list.files()
file.info(filelist_full)$mtime)
max(file.info(filelist_full)$mtime)
file.info(paste0(ctr,".Rdata"))$mtime
max(file.info(filelist_full)$mtime) > file.info(paste0(ctr,".Rdata"))$mtime | is.na(file.info(paste0(ctr,".Rdata"))$mtime
)
# meta data
message("preparing meta data")
fname_data       <- get_meta_from_fname(filelist_full,T)
within_text_data <- link_files_get_date(filelist_full,T)
data_texts  <- cbind(fname_data, within_text_data)
text_meta   <- data_texts
names(data_texts) <- c("t_id", "t_date", "t_dplus", "t_country", "t_daccept", "t_dpromul", "t_denact")
fname_data
within_text_data
message("preparing meta data")
fname_data       <- get_meta_from_fname(filelist_full,T)
within_text_data <- link_files_get_date(filelist_full,T)
data_texts  <- cbind(fname_data, within_text_data)
text_meta   <- data_texts
names(data_texts) <- c("t_id", "t_date", "t_dplus", "t_country", "t_daccept", "t_dpromul", "t_denact")
# text data for upload
message("preparing text data")
data_lines      <- link_files_get_text(linkage_env)
matcher                <- match(data_lines$id, corpus_env$coding$id)
data_lines$corpus_code <- corpus_env$coding$code[ matcher ]
data_lines$corpus_memo   <- ifelse( grepl("#ยง# autocode",corpus_env$coding$memo[ matcher ]),
"", corpus_env$coding$memo[ matcher ] )
names(data_lines) <- c( "tl_id", "tl_text", "tl_lnr", "tl_t_id", "tl_relevant", "tl_wds_raw",
"tl_wds_clean", "tl_corpus_code", "tl_corpus_memo")
data_lines$tl_text <- enc2utf8(data_lines$tl_text)
data_lines$tl_corpus_memo <- enc2utf8(data_lines$tl_corpus_memo)
data_lines$tl_corpus_code[ is.na(data_lines$tl_corpus_code) ] <- 999
data_line
data_lines
# linkage data
message("preparing linkage data")
for(i in seqalong(linkage_env)){
tbc <- eval(as.name(linkage_env[i]))$RESULTS
check_diff(tbc)
}
system.time(data_linkage <- link_files_get_linkage() )
names(data_linkage) <- c("ll_tl_id1", "ll_tl_id2", "ll_sim", "ll_sim_wd", "ll_diff",
"ll_diff_wd", "ll_type", "ll_t_id1", "ll_t_id2",
"ll_tl_lnr1", "ll_tl_lnr2", "ll_minmaj_code", "ll_minmaj_coder",
"ll_minmaj_memo", "ll_linkage_coder")
data_linkage$ll_minmaj_memo <- enc2utf8(data_linkage$ll_minmaj_memo)
# text data for testing
text_texts <- link_files_get_text_only(linkage_env,T)
link_texts <- link_files_get_text_only(linkage_env,F)
# script for making a span data set
# with all variables in isom
# script for joining / merging erd, isor, parlgov,
#### setting things up =========================================================
try(setwd("z:/gesch\u00e4ftsordnungen/database/aggregats/"))
try(setwd("~/z/Database/aggregats/"))
library(idep)
library(dplyr)
library(foreign)
#### loading data ==============================================================
# isor
load("isor.Rdata")
isor[,1:8]
isor  <-
isor  %>%
rename(
so_id      = t_id,
so_start   = t_date,
so_end     = t_date_lead,
so_dplus   = t_dplus,
so_daccept = t_daccept,
so_dpromul = t_dpromul,
so_denact  = t_denact
)
# end dates for last observations -> max of end-of-study or start-of-so
last_so <-
isor %>%
arrange(so_id)  %>%
group_by(ctr)  %>%
summarise(id=last(so_id), last(so_end)) %>%
`[[`("id")
isor[isor$so_id %in% last_so, "so_end"] <-
apply( cbind( isor[isor$so_id %in% last_so, "so_start"], as.Date("2010-01-01")), 1, max)
# isor so_length
isor <-
isor  %>%
mutate(
so_length = so_end - so_start
)
# erd
load("../external_data/erd_cleaned_up.Rdata")
erd[,1:11]
erd <-
erd %>%
mutate(
erd_cab_id = cab_id
)
# pg / mp
load("../external_data/cmp_parlgov_cabinets_ideo_confl_volatility.Rdata")
cabinets[,1:10]
# majority requirement
load("../external_data/maj_req.Rdata")
# veto points
load("../external_data/veto_pts.Rdata")
#### creating isos data set ====================================================
### getting all spans
#   (by expanding time spans to single days,
#    match both data sources on them,
#    aggregate if possible
#   )
isos <- data_frame()
countries <- sort(unique(c(erd$ctr, isor$ctr)))
for (i in seq_along(countries) ) {
ctri <- countries[i]
df1 <-
isor  %>%
filter(ctr==ctri) %>%
select(so_id, so_start, so_end) %>%
as.data.frame()
df2 <-
erd  %>%
filter(ctr==ctri) %>%
select(cab_id, cab_in, cab_out) %>%
as.data.frame()
isos_tmp         <- merger_for_time_spans(df1, df2) %>% arrange(span_start, so_id, cab_id)
isos_tmp$ctr     <- ctri
isos_tmp$span_id <- isos_tmp$span_id + which(sort(unique(c(erd$ctr, isor$ctr))) %in% ctri) * 10000
isos             <- rbind(isos, isos_tmp )
}
isos <- as_data_frame(isos)
#### adding dates of erd and isom to isos
isos <-
isos  %>%
left_join(isor[, c("so_start", "so_end", "so_id")]) %>%
left_join(erd[, c("cab_in", "cab_out", "cab_id")])
### add minimum date to isor to serve as proxy for reform acceptance
isor$so_mindate <-
apply(
data.frame(
isor$so_start,
isor$so_denact,
isor$so_daccept,
isor$so_dpromul
),
1,
min, na.rm=TRUE
) %>%
as.Date()
seq_dim1(isos)
isos_split <- NULL
for( i in seq_dim1(isos)){
tmp      <- isos[i,]
tmp_ctr  <- tmp$ctr
tmp_soid <- tmp$so_id
spl <-
isor %>%
filter(
so_mindate %within% interval(tmp$span_start, tmp$span_end),
ctr   == tmp_ctr,
so_id != tmp_soid
) %>%
select(
so_mindate,
so_id
)
tmp_spl <-
split_timespan_after(
start     = tmp$span_start,
end       = tmp$span_end,
splitdate = spl$so_mindate
)
res <-
tmp[rep(1, dim1(tmp_spl)),]
res$span_start     = tmp_spl$start
res$span_end       = tmp_spl$end
isos_split <- rbind(isos_split, res)
if((i %% 100)==0){
cat(".")
}
}
seq_dim1(isos)
max(seq_dim1(isos))
### redo span ids (duplicated due to splitting)
countries <- sort(unique(c(erd$ctr, isor$ctr)))
isos %>%
arrange(ctr, span_start, span_end, cab_id)
for( i in seq_along(countries)){
isos$span_id[isos$ctr==countries[i]] <-
seq_along(isos$span_id[isos$ctr==countries[i]]) + 10000*i
}
ctri <- "aut"
isos_split$span_outcome[isos_split$ctr==ctri]
isos_split$span_outcome
### redo span ids (duplicated due to splitting)
countries <- sort(unique(c(erd$ctr, isor$ctr)))
isos %>%
arrange(ctr, span_start, span_end, cab_id)
for( i in seq_along(countries)){
isos$span_id[isos$ctr==countries[i]] <-
seq_along(isos$span_id[isos$ctr==countries[i]]) + 10000*i
}
isos_split$span_outcome
as.integer(
isos_split$span_end[isos_split$ctr==ctri] %in%
isor$so_mindate[isor$ctr==ctri]
)
isos %>% filter(ctr=="aut")
isos %>% filter(ctr=="deu")
isos_split$span_outcome <- NA
isos %>% filter(ctr=="deu")
isos_split %>% filter(ctr=="deu")
isos_split %>% filter(ctr=="deu") %>% head()
isos_split$span_outcome <- NA
for(ctri in countries){
isos_split$span_outcome[isos_split$ctr==ctri] <-
as.integer(
isos_split$span_end[isos_split$ctr==ctri] %in%
isor$so_mindate[isor$ctr==ctri]
)
}
isos_split %>% filter(ctr=="deu") %>% head()
isos_split %>% filter(is.na(span_id)) %>% head()
isos_split %>% filter(is.na(so_id)) %>% head()
isos_split %>% filter(is.na(so_id)) %>% head(50)
isos_split %>% filter(is.na(so_id))
isos_split %>% filter(is.na(so_id)) %>% head(60)
isos_split$span_outcome[is.na(isos_split$so_id)] <- NA
#### decide which spans have a reform // outcome of span
isos_split$span_outcome <- NA
for(ctri in countries){
isos_split$span_outcome[isos_split$ctr==ctri] <-
as.integer(
isos_split$span_end[isos_split$ctr==ctri] %in%
isor$so_mindate[isor$ctr==ctri]
)
}
# if there is no so_id this span was not under obervation
isos_split$span_outcome[is.na(isos_split$so_id)] <- NA
isos_split
isos_split %>% head()
isos_split %>% head(10)
isos_split %>% head(30)
isos_split %>% head(40)
isos_split %>% head(50)
isos_split %>% head(100)
sum(isos_split$span_outcome, na.rm=TRUE)
dim(isos)
dim(isor)
# script for checking link data and uploading it to server
#### setting things up =========================================================
message("\n")
library(idep)
library(dplyr)
library(RMySQL)
'%.%' <- function(a,b) paste0(a,b)
message("\n")
# error handling
if( !interactive() ){
options(error = quote({email_error("undefined error in check and upload" , s=ctr, anyways=T); q(save = "no")}) )
}
# connection function
get_ready <- function(){
lapply( dbListConnections( dbDriver( drv = "MySQL")), dbDisconnect)
source("~/DBConnections/so_local.r")
#source("~/DBConnections/so_latin1_local.r")
#source("~/DBConnections/DBSOconnection.r")
}
# setting working directory
try(setwd("Z:/Gesch\u00e4ftsordnungen/database/rawdata"))
try(setwd("~/z/Database/rawdata"))
countries <- list.dirs(".", FALSE, FALSE)
countries
ctr<-"AUT"
# script for checking link data and uploading it to server
#### setting things up =========================================================
message("\n")
library(idep)
library(dplyr)
library(RMySQL)
'%.%' <- function(a,b) paste0(a,b)
message("\n")
# error handling
if( !interactive() ){
options(error = quote({email_error("undefined error in check and upload" , s=ctr, anyways=T); q(save = "no")}) )
}
# connection function
get_ready <- function(){
lapply( dbListConnections( dbDriver( drv = "MySQL")), dbDisconnect)
source("~/DBConnections/so_local.r")
#source("~/DBConnections/so_latin1_local.r")
#source("~/DBConnections/DBSOconnection.r")
}
# setting working directory
try(setwd("Z:/Gesch\u00e4ftsordnungen/database/rawdata"))
try(setwd("~/z/Database/rawdata"))
countries <- list.dirs(".", FALSE, FALSE)
countries
# commandline argument evaluation
eval_cl_args()
if( !exists("ctr") ){
stop(
paste0(
"no country given choose one of these:\n",
paste0(countries, collapse = ", "),
"\ne.g.: R < file.R > file.rout --args ctr='AUT'"
)
}else{
message("### ============================================================== ###")
message("\n",ctr,"\n")
}
#### getting data ==============================================================
message("preparing data ... ")
# select linkage files
# link_files_select()
linkage_path <-
ifelse(
file.exists(ctr %.% "/coded"),
ctr %.% "/coded",
ctr %.% "/linked"
)
link_files_select(
list.files(linkage_path, full.names=T )
)
head(filelist_full,  1)
head(filelist_fname, 1)
head(filelist_path,  1)
country_path
country
# load linkage files
link_files_load(filelist_full)
linkage_env
ls(linkage_env001)
# select corpus file
# corpus_file_select()
corpus_file_select(
list.files(
paste0(ctr,"/corpus"),
full.names=T
)
corpus_file_full
corpus_file_fname
corpus_file_path
# load corpus file
corpus_file_load()
ls(corpus_env)
# preapre data for matching
corpus_data_prepare()
iffer <- max(file.info(filelist_full)$mtime) > file.info(paste0(ctr,".Rdata"))$mtime | is.na(file.info(paste0(ctr,".Rdata"))$mtime)
iffer
iffer <- T
